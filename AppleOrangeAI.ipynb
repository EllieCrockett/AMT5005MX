{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Hz7iQwYNBN"
      },
      "source": [
        "AMT5005MX Python Project AppleOrangeAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Installs PIP necessary for code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.9.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\myles\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.24.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.2.6)\n",
            "Requirement already satisfied: torch==2.9.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.9.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (12.0.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.9.0->torchvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\myles\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.9.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.9.0->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.9.0->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.9.0->torchvision) (2025.10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch==2.9.0->torchvision) (3.0.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\myles\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (12.0.0)\n",
            "Requirement already satisfied: pyparsing>=3 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\myles\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\myles\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (2.3.1)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (2.2.6)\n",
            "Requirement already satisfied: packaging in c:\\users\\myles\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: pillow in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (12.0.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (6.33.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (65.5.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in c:\\users\\myles\\appdata\\roaming\\python\\python311\\site-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\myles\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install torch\n",
        "%pip install torchvision\n",
        "%pip install matplotlib\n",
        "%pip install scikit-learn\n",
        "%pip install tensorboard\n",
        "%pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Necessary Pytorch Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CCZ30wGEYMj-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adjustable Hyperparamaters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Zub_QPsCs_F4"
      },
      "outputs": [],
      "source": [
        "num_classes = 2 # DO NOT CHANGE ‘num_classes’: The number of classes in our new classification task.\n",
        "batch_size = 32 #- ‘batch_size’: Number of images processed at a time. A typical value is 32 or 64.\n",
        "num_epochs = 1 #- ‘num_epochs’: Number of complete passes through the training dataset. Here we use 1 for demonstration, but in practice, you may use 10, 20, or more.\n",
        "learning_rate = 0.001 #- ‘learning_rate’: The rate at which the model updates its weights during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jr5vSB3KtcGf"
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        " 'train': transforms.Compose([\n",
        " transforms.Resize((224, 224)), #all images are resized to VVG16, fixing outliers and making the images optimal for VGG16\n",
        " transforms.RandomHorizontalFlip(), #Randomly flips the images horizontally, this effectively allows for more training and test material by doubling the number of available images (flipped and unflipped)\n",
        " transforms.ToTensor(),\n",
        " transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) #Normalizes the pixel values (mandatory for using my pre-trained model)\n",
        " ]),\n",
        " 'val': transforms.Compose([\n",
        " transforms.Resize((224, 224)),\n",
        " transforms.ToTensor(),\n",
        " transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        " ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Root/ Relative Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1q-0b5gZ4bpf"
      },
      "outputs": [],
      "source": [
        "#Relative path based off the name of the files, change if renamed/moved\n",
        "root_dir = './apple_orange'\n",
        "train_root = root_dir + '/train'\n",
        "val_root = root_dir + '/val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Loading the training and validation datasetts using 'ImageFolder' for later use\n",
        "train_dataset = datasets.ImageFolder(root=train_root, transform=data_transforms['train'])\n",
        "val_dataset = datasets.ImageFolder(root=val_root, transform=data_transforms['val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'orange']\n"
          ]
        }
      ],
      "source": [
        "#creates data loaders to fectch data in batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) \n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "print(train_dataset.classes) #Print class names, should be ['apple', 'orange']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reading CSV files using Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#imports pandas and prints the current pandas version\n",
        "import pandas\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our Dataframe....              image_id      domain  split                  image_path\n",
            "0     n07740461_10011  B (Orange)   test   testB/n07740461_10011.jpg\n",
            "1     n07740461_10012   A (Apple)  train  trainA/n07740461_10012.jpg\n",
            "2     n07740461_10019   A (Apple)  train  trainA/n07740461_10019.jpg\n",
            "3     n07740461_10037   A (Apple)  train  trainA/n07740461_10037.jpg\n",
            "4     n07740461_10065   A (Apple)  train  trainA/n07740461_10065.jpg\n",
            "...               ...         ...    ...                         ...\n",
            "2523   n07749192_9883  B (Orange)  train   trainB/n07749192_9883.jpg\n",
            "2524   n07749192_9889  B (Orange)  train   trainB/n07749192_9889.jpg\n",
            "2525    n07749192_992  B (Orange)  train    trainB/n07749192_992.jpg\n",
            "2526    n07749192_993  B (Orange)  train    trainB/n07749192_993.jpg\n",
            "2527    n07749192_998  B (Orange)  train    trainB/n07749192_998.jpg\n",
            "\n",
            "[2528 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "#input CSV file\n",
        "dataFrame = pd.read_csv('./apple_orange/metadata.csv')\n",
        "#Check CSV file is loaded correctly\n",
        "print(\"Our Dataframe....\", dataFrame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yXiA6F74bwG",
        "outputId": "5bf28053-0759-4d29-b39d-7646ffb32d79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Myles\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Myles\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "#loads the Pre-Trained VGG16 Model\n",
        "model = models.vgg16(pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Adjustment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aiGMY42L4byT"
      },
      "outputs": [],
      "source": [
        "#Freezes unnecessary parts of the model to save resources\n",
        "for param in model.features.parameters():\n",
        " param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Lg4Dm7WX4b1f"
      },
      "outputs": [],
      "source": [
        "#modifies the final layer to match the number of classes in our task\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AjDfRAlR4b3o"
      },
      "outputs": [],
      "source": [
        "#creates a Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIuHWZG47THM"
      },
      "source": [
        "Model Finetuning (Takes a long time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "729CKZTw4b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1, Loss: 0.6742\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "   model.train()\n",
        "   running_loss = 0.0\n",
        "   for inputs, labels in train_loader:\n",
        "     inputs, labels = inputs.to(device), labels.to(device)\n",
        "     optimizer.zero_grad()\n",
        "     outputs = model(inputs)\n",
        "     loss = criterion(outputs, labels)\n",
        "     loss.backward()\n",
        "     optimizer.step()\n",
        "     running_loss += loss.item() * inputs.size(0)\n",
        "   epoch_loss = running_loss / len(train_loader.dataset)\n",
        "   print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uzm0y1nc73EO"
      },
      "source": [
        "Model Evaluation (Takes a long time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zr51Le3a7vp7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9689\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    print(f'Validation Accuracy: {val_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving the trained model for later use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2gASmbXd7wj1"
      },
      "outputs": [],
      "source": [
        "#saves the trained model\n",
        "torch.save(model.state_dict(), 'vgg16_finetuned.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QFU4ryGD7wl8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the saved state dictionary\n",
        "state_dict = torch.load('vgg16_finetuned.pth')\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reading CSV files using Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "#imports pandas and prints the current pandas version\n",
        "import pandas\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our Dataframe....              image_id      domain  split                  image_path\n",
            "0     n07740461_10011  B (Orange)   test   testB/n07740461_10011.jpg\n",
            "1     n07740461_10012   A (Apple)  train  trainA/n07740461_10012.jpg\n",
            "2     n07740461_10019   A (Apple)  train  trainA/n07740461_10019.jpg\n",
            "3     n07740461_10037   A (Apple)  train  trainA/n07740461_10037.jpg\n",
            "4     n07740461_10065   A (Apple)  train  trainA/n07740461_10065.jpg\n",
            "...               ...         ...    ...                         ...\n",
            "2523   n07749192_9883  B (Orange)  train   trainB/n07749192_9883.jpg\n",
            "2524   n07749192_9889  B (Orange)  train   trainB/n07749192_9889.jpg\n",
            "2525    n07749192_992  B (Orange)  train    trainB/n07749192_992.jpg\n",
            "2526    n07749192_993  B (Orange)  train    trainB/n07749192_993.jpg\n",
            "2527    n07749192_998  B (Orange)  train    trainB/n07749192_998.jpg\n",
            "\n",
            "[2528 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "#input CSV file\n",
        "dataFrame = pd.read_csv('./apple_orange/metadata.csv')\n",
        "#Check CSV file is loaded correctly\n",
        "print(\"Our Dataframe....\", dataFrame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_set' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m cm = confusion_matrix(\u001b[43mtest_set\u001b[49m.targets, test_preds.argmax(dim=\u001b[32m1\u001b[39m))\n\u001b[32m      2\u001b[39m classes = (\u001b[33m'\u001b[39m\u001b[33mapples\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33moranges\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m plt.figure(figsize=(\u001b[32m2\u001b[39m,\u001b[32m2\u001b[39m))\n",
            "\u001b[31mNameError\u001b[39m: name 'test_set' is not defined"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(test_set.targets, test_preds.argmax(dim=1))\n",
        "classes = ('apples', 'oranges')\n",
        "plt.figure(figsize=(2,2))\n",
        "plot_confusion_matrix(cm, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(test_set.targets, test_preds.argmax(dim=1))\n",
        "classes = ('apples', 'oranges')\n",
        "plt.figure(figsize=(2,2))\n",
        "plot_confusion_matrix(cm, classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you can the training loss curve also, something like attached in the diagram."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
